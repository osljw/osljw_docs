

# hive
```
hive -e "<cmd1>; <cmd2>"
```
```
show databases
use <database>
show tables
show partitions <table>
desc formatted <table>
desc formatted <database>.<table>
```

# hive engine
```
set hive.execution.engine=mr;
set hive.execution.engine=spark;
```
SparkSQL和hive on spark使用的都是spark engine


# hive sql

> 可以先加上限制条件减少数据量，快速测试执行，然后再去除限制条件正式运行任务

# hive set
columns names of the table 
```
set hive.cli.print.header=true;
```
## 分组统计

使用group by获得去重用户
```
hive -e "select u,count(*) from test_table where dt='2019-09-01' and h=12 group by u"  > log.stdout 2>log.stderr &
```

uv 日活统计
```
hive -e "use gen; select dt,count(*) from (select dt,u from table_name where dt>='2019-09-01' group by dt,u)t group by dt;"
```

## 子查询 sub-queries

统计用户数量uv
- group by方式
```
hive -e "select count(*) from (select u,count(*) from test_table where dt='2019-09-01' and h=12 group by u)t1"
```
- count distinct可能造成倾斜(只有一个reduce)，配合group by进行分组增加reduce
```
SELECT
  SUM(mau_part) mau
FROM
(
  -- 内层SELECT分别进行COUNT(DISTINCT)计算
  SELECT
    substr(uuid, 1, 3) uuid_part,
    COUNT(DISTINCT substr(uuid, 4)) AS mau_part
  FROM detail_sdk_session
  WHERE partition_date >= '2016-01-01' AND partition_date <= now
  GROUP BY substr(uuid, 1, 3)
) t;
```

## join
1. join
2. 排序去重方式完成join任务

```
ROW_NUMBER() OVER(PARTITION BY COLUMN ORDER BY COLUMN DESC)
```
- PARTITION BY COLUMN 表示按COLUMN列进行分组
- ORDER BY COLUMN DESC表示在分组内部按列COLUMN进行降序排列
- ROW_NUMBER() OVER()表示在分组内部，排序之后标记行号 

## hive in/exists子查询
``` 
select * from a where a.key in (select b.key from b)
```

使用left semi join
```
select * from a left semi join b on (a.key = b.key)
```