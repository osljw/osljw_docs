
# shell

# grep
```
# 查找多个字段
grep -P "field1|field2|field3" <file>

# 只输出匹配字段
grep -o -P "(regex)"
```

# awk

匹配提取多个字段， 确认awk的类型，通过man awk，可以看出awk是mawk还是gawk


写成脚本文件，awk_log.awk文件内容如下：
```
#!/usr/bin/awk -f
# 通过设置flag控制是否进行过滤
 {flag=0}
 match($0, /\[QUERY\]/) {flag=1}; 
 match($0, /(rid:[a-z0-9]*)/) { a[0]=substr($0, RSTART, RLENGTH);}; 
 match($0, /latency:[0-9]*/)  { a[1]=substr($0, RSTART, RLENGTH);};
 {if(flag) print $0,a[0],a[1]}
```
mawk的match函数为两个参数， 第一个为字符串， 第二个为匹配的正则表达式

awk命令由一个或多个pattern{action}的格式组成， 这里每个match函数负责提取一个字段

运行方法： chmod +x awk_log.awk && ./awk_log.awk log.txt

# 命令结果作为其他命令的文件输入
```shell
set -u
set -e

data_file=$1
# count from one
line_num=$2                                                                                                            
echo "=================="
echo "line_num=$line_num"
echo "=================="

row_data=`sed -n "${line_num}p;d" $data_file`
col_data=`awk -F"\t" '{for(i=1;i<=NF;i++) print $i}' <(echo "$row_data")`
schema=`grep -v "#" conf/schema.yaml | grep -v "^$"`
paste <(echo "$schema") <(echo "$col_data")
```

- ```sed -n "${start_line_num},${end_line_num}p"``` 提取一个文件中第line_num行， 行号从1开始计数
- ```echo "$schema"```和```echo $schema```的区别，变量带引号时，变量中的newline符号不会丢失

# sed
从文件的第n行开始输出
```
sed -n '2,$p' file
```

替换文件内容
```
sed -i 's/^--ad_redis_host=.*$/--ad_redis_host=10.0.0.1/g' $ROOT_DIR/conf/gflags.conf
```

# 文件过滤
## 忽略某个模式的后几行
忽略thread.txt文件中，包含pthread_cond_wait字符串的行和其随后的行，共计8行
awk -v nlines=8 '/.*pthread_cond_wait.*/ {for (i=0; i<nlines; i++) {getline}; next} 1' thread.txt


# find
```
# 忽略./test目录
find . -name "*.cpp" -not -path "./test*"

# 查找大文件
find . -type f -size +800M
find . -type f -size +300M -exec ls -l {} \;

```

exec 和 xargs
```
# -exec 将所有匹配结果同时传递给命令
find . -type f -size +300M -exec ls -l {} \;

# xargs 可以控制传递给命令的参数
find . -type f -size +300M | xargs ls -l
```

# 正则表达式
```
. 单个任意字符
? 匹配0个或1个

```


## 机器的启动时间点
who -b
## 查看机器历史登录用户
who /var/log/wtmp 机器的用户登录历史

# 内存
## 内存使用情况
free -h

```
             total       used       free     shared    buffers     cached
Mem:          252G       248G       3.7G       1.1G       169M       187G
-/+ buffers/cache:        60G       191G
Swap:         8.0G       4.1G       3.9G
```
第二行的（-/+ buffers/cache:）表示在第一行used和free列基础上减去和加上buffers/cache的使用

cached是cpu与内存间的， 读缓冲

buffers是内存与磁盘间的，都是为了解决速度不对等的问题

sync 将buffers写入磁盘


# 系统状态
https://github.com/sysstat/sysstat

## 进程的上下文切换
```shell
pidstat -w -p <pid>

02:51:58 PM   UID       PID   cswch/s nvcswch/s  Command
02:51:58 PM  1018     75278      0.75      0.00  rankserver

# 每秒刷新输出上下文切换情况
pidstat -w 1 -p 41242

02:57:36 PM   UID       PID   cswch/s nvcswch/s  Command
02:57:37 PM  1020     41242    534.00      0.00  rankserver
02:57:38 PM  1020     41242    512.00      0.00  rankserver
02:57:39 PM  1020     41242    554.00      0.00  rankserver

# 线程的每秒上下文切换情况
pidstat -wt 1 -p <pid>
```
cswch/s是主动地上下文切换，nvcswch/s是被动执行上下文切换的次数。



# 进程

## 查看进程的线程
ps -T -p [pid]
```
   PID   SPID TTY          TIME CMD
185260 185260 ?        00:00:04 rankserver_qa
```

top -H -p [pid] 

## 进程的网络连接和端口


进程打开的文件描述符
```
lsof -p  [pid]  
```

# 文件
查看访问文件的进程
```shell
lsof [file]
```

根据端口找进程信息
```shell
lsof -i:<port>
```

# 网络
```
netstat -nap | grep [pid]

# 查看机器正在listen的端口
netstat -tlp

-p 显示进程名称信息
-a 显示所有连接(LISTEN，CONNECTED， ESTABLISHED)
-l 只显示listen状态的连接
-n 不显示域名而是显示ip
```



# 磁盘

查看硬盘种类
lsblk -d -o name,rota
rota=1 表示硬盘可旋转，所以为机械硬盘

tps：每秒I/O次数=[(Δrd_ios+Δwr_ios)/Δt]

r/s：每秒读操作的次数=[Δrd_ios/Δt]

w/s：每秒写操作的次数=[Δwr_ios/Δt]

await：每个I/O平均所需的时间=[Δrd_ticks+Δwr_ticks]/[Δrd_ios+Δwr_ios]
（不仅包括硬盘设备处理I/O的时间，还包括了在kernel队列中等待的时间。）

util： 硬盘设备的繁忙比率（该设备有I/O（即非空闲）的时间比率）[Δio_ticks/Δt]

iostat -dxk 2 2

 /proc/<pid>/io 进程的io累计信息


# 包管理
查找包

apt-cache search [package]

查看包的状态，是否安装，版本信息等

dpkg -s python-dev


# 用户和组
## 查看当前用户
whoami

## 用户属于哪几个用户组
groups <user> 


# date shell 时间区间

shell 
```
set -eu

input_start=$1
input_end=$2

start_dt=$(date -I -d "$input_start")
end_dt=$(date -I -d "$input_end")

echo "start_dt: $start_dt"
echo "end_dt: $end_dt"

cur_dt=$start_dt
while [ "$(date -d "$cur_dt" +%Y%m%d)" -le "$(date -d "$end_dt" +%Y%m%d)" ]; do
    echo $cur_dt
    cur_dt=$(date -I -d "$cur_dt + 1 day")
done
```



# rsync

```
rsync -a source/ destination --exclude='dir1/*'

# --dry-run 测试命令影响
rsync -anv source/ destination
```

/etc/rsyncd.conf 服务配置
```
# gloable params
uid = root
gid = root
use chroot = no
max connections = 4
strict modes =yes #
port = 8081
log file = /var/log/rsync.log # 方便调试连接错误

# module params
[module1] # 客户端推送文件时，指定目的路径时，使用模块名
path = /data/module1/sync_data # 推送到该模块时，文件保存在该目录下
comment = xxx
read only = false
list = no # 不允许客户端查看该目录下的已有文件
#auth users = sumitli
secrets file = /etc/rsync.pass 
hosts allow = <client_ip> # 允许连接的客户端ip
hosts deny = 0.0.0.0
```


客户端推送文件到服务器
```
sudo rsync --port=8081 --password-file=/etc/rsync.pass  -av ./test_src_file root@server_ip::module1
```